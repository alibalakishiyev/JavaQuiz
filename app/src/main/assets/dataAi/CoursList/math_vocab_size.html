<!DOCTYPE html>
<html lang="az">
<head>
    <meta charset="UTF-8">
    <title>vocab_size AÃ§Ä±qlamasÄ±</title>
    <style>
        body {
          font-family: "Segoe UI", sans-serif;
          padding: 30px;
          background-color: #f8f9fa;
          color: #333;
        }
        h1, h2 {
          color: #2c3e50;
        }
        .code-block {
          background-color: #eef;
          padding: 10px;
          border-radius: 6px;
          font-family: Consolas, monospace;
          margin: 10px 0;
        }
        .highlight {
          background-color: #fff3cd;
          border-left: 6px solid #ffc107;
          padding: 10px;
          margin: 20px 0;
        }
        .formula {
            background: #e3f2fd;
            border-left: 6px solid #2196f3;
            padding: 10px;
            margin: 15px 0;
            font-family: monospace;
            color: black;
        }
        .note {
          background-color: #e8f5e9;
          padding: 10px;
          border-left: 6px solid #66bb6a;
          margin: 10px 0;
        }
    </style>
</head>
<body>

<h1>ğŸ”  <code>vocab_size = len(self.tokenizer)</code> AÃ§Ä±qlamasÄ±</h1>

<div class="formula">
    config = GPT2Config(<br>
    &nbsp;&nbsp;&nbsp;&nbsp;vocab_size = len(self.tokenizer),<br>
    &nbsp;&nbsp;&nbsp;&nbsp;...<br>
    )
</div>

<h2>ğŸ“Œ NÉ™ demÉ™kdir?</h2>
<div class="formula">
    <strong><code>vocab_size</code></strong> â€” modelin qÉ™bul etdiyi bÃ¼tÃ¼n unikal tokenlÉ™rin (alt sÃ¶z, sÃ¶z, simvol vÉ™ s.) sayÄ±nÄ± gÃ¶stÉ™rir.
    Bu, tokenizer-in <code>.vocab</code> vÉ™ ya <code>.get_vocab()</code> nÉ™ticÉ™sindÉ™ alÄ±nan lÃ¼ÄŸÉ™tin uzunluÄŸudur.
</div>

<h2>ğŸ’¡ Riyazi mÉ™na</h2>
<div class="formula">
    vocab_size = Tokenizer-dÉ™ki bÃ¼tÃ¼n unikal tokenlÉ™rin sayÄ±
</div>

<h3>MÉ™sÉ™lÉ™n:</h3>
<div class="formula">
    ÆgÉ™r tokenizer-dÉ™ 94,196 token varsa â†’ <code>vocab_size = 94196</code>
</div>

<h2>ğŸ”¢ ModeldÉ™ necÉ™ istifadÉ™ olunur?</h2>
<div class="formula">
    <ul>
        <li>HÉ™r token Ã¼Ã§Ã¼n <code>n_embd</code> Ã¶lÃ§Ã¼lÃ¼ vektor saxlanÄ±lÄ±r (embedding layer).</li>
        <li>Embedding qatÄ±nÄ±n Ã¶lÃ§Ã¼sÃ¼ belÉ™ hesablanÄ±r:</li>
    </ul>
</div>

<div class="formula">
    <strong>Embedding matrix Ã¶lÃ§Ã¼sÃ¼:</strong> vocab_size Ã— n_embd <br>
    MÉ™sÉ™lÉ™n: 94,196 Ã— 768 = 72,307,328 parametr
</div>

<h2>â— NiyÉ™ vacibdir?</h2>
<div class="formula">
    <ul>
        <li>ÆgÉ™r vocab_size dÃ¼zgÃ¼n gÃ¶stÉ™rilmÉ™zsÉ™, model ya <u>tokeni tanÄ±mayacaq</u>, ya da <u>Ã§É™kilÉ™ri yanlÄ±ÅŸ matrisa Ã¶lÃ§Ã¼sÃ¼ndÉ™ saxlayacaq</u>.</li>
        <li>Buna gÃ¶rÉ™ <strong>Tokenizer vÉ™ Model</strong> eyni <code>vocab_size</code> Ã¼zÉ™rindÉ™ qurulmalÄ±dÄ±r.</li>
    </ul>
</div>

<h2>âœ… NÉ™ticÉ™</h2>
<div class="formula">
    <strong><code>vocab_size = len(self.tokenizer)</code></strong> dedikdÉ™ mÉ™qsÉ™d:
    <br><br>
    Tokenizer-dÉ™ neÃ§É™ unikal token varsa, onu model konfiqurasiyasÄ±nda istifadÉ™ etmÉ™kdir ki, giriÅŸlÉ™r doÄŸru kodlaÅŸdÄ±rÄ±lsÄ±n vÉ™ model dÃ¼zgÃ¼n iÅŸlÉ™sin.
</div>

</body>
</html>
