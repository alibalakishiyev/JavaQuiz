<!DOCTYPE html>
<html lang="az">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>AzGPT TÉ™lim Skripti - MetodlarÄ±n Ä°zahÄ±</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 20px;
            line-height: 1.6;
            background: #f9f9f9;
            color: #333;
        }
        h1, h2, h3 {
            color: #004d99;
        }
        pre {
            background: #eee;
            border-left: 5px solid #004d99;
            padding: 10px;
            overflow-x: auto;
        }
        .method {
            background: #fff;
            padding: 15px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgb(0 0 0 / 0.1);
        }
        .code {
            font-family: Consolas, monospace;
            background: #272822;
            color: #f8f8f2;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
        }
        .note {
            font-style: italic;
            color: #666;
        }
    </style>
</head>
<body>
<h1>AzGPT - AzÉ™rbaycan Dili Ã¼Ã§Ã¼n GPU Optimize EdilmiÅŸ GPT-2 TÉ™lim Skripti</h1>
<p><strong>MÉ™qsÉ™d:</strong> AzÉ™rbaycan dilindÉ™ GPT-2 modeli yaratmaq Ã¼Ã§Ã¼n GPU istifadÉ™ edÉ™rÉ™k tÉ™lim prosesi. TÉ™lim gediÅŸatÄ±nÄ± vizual olaraq izlÉ™mÉ™k Ã¼Ã§Ã¼n É™lavÉ™ funksionallÄ±q var.</p>

<h2>Ãœmumi Skript Strukturunun Ä°cmalÄ±</h2>
<p>Skript aÅŸaÄŸÄ±dakÄ± hissÉ™lÉ™rdÉ™n ibarÉ™tdir:</p>
<ul>
    <li>Konfiqurasiya vÉ™ parametrlÉ™r (qovluq yollarÄ±, tÉ™lim parametrlÉ™ri, GPU istifadÉ™si)</li>
    <li>Vizualizasiya vÉ™ tÉ™lim prosesinin izlÉ™nmÉ™si Ã¼Ã§Ã¼n xÃ¼susi siniflÉ™r</li>
    <li>Modelin vÉ™ tokenizer-in yÃ¼klÉ™nmÉ™si vÉ™ hazÄ±rlanmasÄ±</li>
    <li>MÉ™lumatlarÄ±n yÃ¼klÉ™nmÉ™si vÉ™ tokenlÉ™ÅŸdirilmÉ™si</li>
    <li>Modelin tÉ™limi Ã¼Ã§Ã¼n Trainer sinifindÉ™n irsi gÃ¶tÃ¼rÃ¼lmÃ¼ÅŸ xÃ¼susi sinif</li>
    <li>Æsas funksiya vÉ™ proqramÄ±n iÅŸÉ™ salÄ±nmasÄ±</li>
</ul>

<hr/>

<div class="method">
    <h3>1. <code>TrainingVisualizer</code> sinfi</h3>
    <p><strong>VÉ™zifÉ™:</strong> TÉ™lim zamanÄ± itki (loss), qiymÉ™tlÉ™ndirmÉ™ (eval) itkisi vÉ™ GPU yaddaÅŸ istifadÉ™sini toplamaq vÉ™ 100 addÄ±mda bir statistikalarÄ± Ã§ap etmÉ™k.</p>
    <pre class="code">
class TrainingVisualizer:
    def __init__(self):
        self.train_losses = []
        self.eval_losses = []
        self.gpu_memory = []

    def update(self, logs, gpu_stats):
        if 'loss' in logs:
            self.train_losses.append(logs['loss'])
        if 'eval_loss' in logs:
            self.eval_losses.append(logs['eval_loss'])
        if gpu_stats:
            self.gpu_memory.append(gpu_stats['used'])

        if len(self.train_losses) % 100 == 0:
            print(f"\nğŸ“Š Proqress: Step {len(self.train_losses)}")
            print(f"ğŸ“‰ Train Loss: {self.train_losses[-1]:.4f}")
            if self.eval_losses:
                print(f"ğŸ“ˆ Eval Loss: {self.eval_losses[-1]:.4f}")
            if self.gpu_memory:
                print(f"ğŸ’¾ GPU Memory: {self.gpu_memory[-1]:.2f} GB")
        </pre>
    <p class="note">Qeyd: Bu sinif hazÄ±rda tÉ™limdÉ™ istifadÉ™ olunmur, amma statistikalarÄ±n yÄ±ÄŸÄ±lmasÄ± vÉ™ Ã§apÄ± Ã¼Ã§Ã¼n nÉ™zÉ™rdÉ™ tutulub.</p>
</div>

<div class="method">
    <h3>2. <code>GPUTrainer</code> sinfi (Trainer-dÉ™n irsi gÃ¶tÃ¼rÃ¼lmÃ¼ÅŸ)</h3>
    <p><strong>VÉ™zifÉ™:</strong> Hugging Face Trainer sinifindÉ™n irs alaraq tÉ™lim gediÅŸatÄ±nÄ± real-time vizuallaÅŸdÄ±rma, addÄ±m, itki, learning rate, GPU yaddaÅŸÄ± vÉ™ epox mÉ™lumatlarÄ±nÄ± toplamaq vÉ™ qrafik ÅŸÉ™klindÉ™ saxlamaq.</p>

    <ul>
        <li><code>__init__</code>: StatistikalarÄ± saxlamaq Ã¼Ã§Ã¼n dÉ™yiÅŸÉ™nlÉ™ri yaradÄ±r, progress bar Ã¼Ã§Ã¼n dÉ™yiÅŸÉ™nlÉ™r tÉ™yin edir.</li>
        <li><code>log</code>: HÉ™r log mesaj gÉ™ldikdÉ™ statistikalarÄ± toplayÄ±r, progress bar-Ä± yenilÉ™yir, hÉ™r 50 addÄ±mda statistikalarÄ± diskÉ™ yazÄ±r vÉ™ qrafiki yenilÉ™yir.</li>
        <li><code>_update_progress_bar</code>: Progress bar-da itki, validation loss, learning rate, GPU yaddaÅŸ vÉ™ epoch mÉ™lumatlarÄ±nÄ± gÃ¶stÉ™rir.</li>
        <li><code>_save_stats</code>: StatistikalarÄ± JSON fayla yazÄ±r.</li>
        <li><code>_plot_progress</code>: TÉ™lim prosesinin itki, learning rate vÉ™ GPU yaddaÅŸÄ±nÄ±n qrafiklÉ™rini yaradÄ±r vÉ™ fayla yazÄ±r.</li>
    </ul>

    <pre class="code">
class GPUTrainer(Trainer):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.progress_bar = None
        self.stats = {...}
        self.current_epoch = 0
        self.last_log_time = time.time()

    def log(self, logs, start_time=None):
        super().log(logs)
        # statistikalar toplanÄ±r, progress bar yenilÉ™nir, fayllar saxlanÄ±r vÉ™ qrafik Ã§É™kilir

    def _update_progress_bar(self, logs, gpu_mem):
        # progress bar mÉ™lumatlarÄ±nÄ± yenilÉ™yir

    def _save_stats(self):
        # statistikalarÄ± JSON-a yazÄ±r

    def _plot_progress(self):
        # itki, learning rate, GPU yaddaÅŸÄ± qrafiklÉ™rini Ã§É™kir vÉ™ yadda saxlayÄ±r
        </pre>
</div>

<div class="method">
    <h3>3. <code>AzerbaijaniGPT2Trainer</code> sinfi</h3>
    <p><strong>VÉ™zifÉ™:</strong> GPT-2 modelinin AzÉ™rbaycan dilinÉ™ uyÄŸun tÉ™limini idarÉ™ etmÉ™k Ã¼Ã§Ã¼n É™sas sinifdir. Tokenizer vÉ™ modelin yaradÄ±lmasÄ±, mÉ™lumatlarÄ±n hazÄ±rlanmasÄ±, tÉ™lim prosesi vÉ™ nÉ™ticÉ™lÉ™rin saxlanmasÄ± burada idarÉ™ olunur.</p>

    <h4>Æsas metodlar:</h4>
    <ul>
        <li><code>__init__</code>: ParametrlÉ™ri saxlayÄ±r (data qovluÄŸu, tokenizer qovluÄŸu, Ã§Ä±xÄ±ÅŸ qovluÄŸu, epoch sayÄ±, batch Ã¶lÃ§Ã¼sÃ¼, Ã¶yrÉ™nmÉ™ sÃ¼rÉ™ti vÉ™ s.).</li>
        <li><code>_print_configuration</code>: TÉ™lim parametrlÉ™ri vÉ™ GPU haqqÄ±nda mÉ™lumatlarÄ± ekrana Ã§ap edir.</li>
        <li><code>initialize_tokenizer</code>: Tokenizer-i diskdÉ™n yÃ¼klÉ™yir, pad token tÉ™yin edir vÉ™ tokenizer Ã¶lÃ§Ã¼sÃ¼nÃ¼ Ã§ap edir.</li>
        <li><code>initialize_model</code>: GPT-2 modelini konfiqurasiya edir vÉ™ GPU/CPU Ã¼zÉ™rinÉ™ yÃ¼klÉ™yir.</li>
        <li><code>prepare_data</code>: MÉ™tn fayllarÄ±nÄ± oxuyur, cÃ¼mlÉ™lÉ™rÉ™ bÃ¶lÃ¼r, tÉ™mizlÉ™yir, Hugging Face Dataset formatÄ±na Ã§evirir, tokenlÉ™ÅŸdirir vÉ™ tÉ™lim/validasiya bÃ¶lmÉ™si yaradÄ±r.</li>
        <li><code>train</code>: TÉ™lim parametrlÉ™rini tÉ™yin edir, GPUTrainer-i yaradaraq tÉ™lim prosesini iÅŸÉ™ salÄ±r, xÉ™talarla iÅŸlÉ™yir, model vÉ™ tokenizer-i yadda saxlayÄ±r.</li>
    </ul>

    <pre class="code">
class AzerbaijaniGPT2Trainer:
    def __init__(self, data_dir, tokenizer_dir, output_dir, epochs, batch_size, learning_rate):
        # parametrlÉ™ri yadda saxlayÄ±r

    def _print_configuration(self):
        # tÉ™lim vÉ™ GPU konfiqurasiyasÄ±nÄ± Ã§ap edir

    def initialize_tokenizer(self):
        # tokenizer-i yÃ¼klÉ™yir, pad token yoxdursa tÉ™yin edir, sÃ¶zlÃ¼k Ã¶lÃ§Ã¼sÃ¼nÃ¼ Ã§ap edir

    def initialize_model(self):
        # GPT2Config yaradÄ±lÄ±r, model konfiqurasiya olunur vÉ™ cihazda (GPU/CPU) yaradÄ±lÄ±r

    def prepare_data(self):
        # MÉ™tn fayllarÄ± oxunur, tÉ™mizlÉ™nir, dataset yaradÄ±lÄ±r, tokenlÉ™ÅŸdirilir, train/test bÃ¶lÃ¼nÃ¼r

    def train(self):
        # TÉ™lim arqumentlÉ™ri qurulur, Trainer yaradÄ±lÄ±r, tÉ™limÉ™ start verilir, nÉ™ticÉ™lÉ™r saxlanÄ±lÄ±r
        </pre>
</div>

<div class="method">
    <h3>4. <code>main()</code> funksiyasÄ±</h3>
    <p><strong>VÉ™zifÉ™:</strong> ProqramÄ±n É™sas giriÅŸ nÃ¶qtÉ™sidir. QovluqlarÄ±n mÃ¶vcudluÄŸunu yoxlayÄ±r, GPU-nun olub-olmamasÄ±nÄ± yoxlayÄ±r, AzÉ™rbaycan GPT-2 tÉ™limÃ§isini yaradÄ±r vÉ™ tÉ™lim prosesini iÅŸÉ™ salÄ±r.</p>

    <pre class="code">
def main():
    print("=" * 50)
    print("AZGPT - AzÉ™rbaycan Dili Ã¼Ã§Ã¼n GPT-2 TÉ™lim ProqramÄ±")
    print(f"BaÅŸlama vaxtÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)

    # QovluqlarÄ±n yoxlanmasÄ±
    if not os.path.exists(DATA_DIR):
        raise ValueError(f"âŒ MÉ™lumat qovluÄŸu tapÄ±lmadÄ±: {DATA_DIR}")
    if not os.path.exists(TOKENIZER_DIR):
        raise ValueError(f"âŒ Tokenizer qovluÄŸu tapÄ±lmadÄ±: {TOKENIZER_DIR}")

    # GPU yoxlanÄ±ÅŸÄ±
    if not torch.cuda.is_available():
        raise RuntimeError("âŒ GPU aÅŸkarlanmadÄ±! ...")

    trainer = AzerbaijaniGPT2Trainer(
        data_dir=DATA_DIR,
        tokenizer_dir=TOKENIZER_DIR,
        output_dir=OUTPUT_DIR,
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        learning_rate=LEARNING_RATE
    )

    try:
        trainer.train()
    except Exception as e:
        print(f"\nâŒ XÉ™ta baÅŸ verdi: {str(e)}")
        raise
    finally:
        print("\n" + "=" * 50)
        print(f"TÉ™lim tamamlandÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 50)
        </pre>
</div>

<div class="method">
    <h3>5. Skriptin iÅŸÉ™ dÃ¼ÅŸmÉ™si</h3>
    <p><strong>VÉ™zifÉ™:</strong> Python skriptinin É™sas modulu kimi iÅŸlÉ™dildiyi halda GPU yaddaÅŸÄ±nÄ± tÉ™mizlÉ™yir vÉ™ <code>main()</code> funksiyasÄ±nÄ± Ã§aÄŸÄ±rÄ±r.</p>
    <pre class="code">
if __name__ == "__main__":
    torch.cuda.empty_cache()
    main()
        </pre>
</div>

<hr/>

<h2>QÄ±sa xÃ¼lasÉ™</h2>
<ul>
    <li><strong>TrainingVisualizer:</strong> TÉ™lim statistikasÄ±nÄ± toplayÄ±b Ã§ap edir (hazÄ±rda aktiv deyil).</li>
    <li><strong>GPUTrainer:</strong> Hugging Face Trainer sinifini geniÅŸlÉ™ndirÉ™rÉ™k tÉ™limin monitorinqini artÄ±rÄ±r vÉ™ vizual statistikalarÄ± yaradÄ±r.</li>
    <li><strong>AzerbaijaniGPT2Trainer:</strong> Modelin, tokenizer-in vÉ™ mÉ™lumatlarÄ±n hazÄ±rlanmasÄ±nÄ± vÉ™ tÉ™lim prosesini idarÉ™ edir.</li>
    <li><strong>main:</strong> BÃ¼tÃ¼n prosesi iÅŸÉ™ salan É™sas funksiyadÄ±r.</li>
</ul>

<p>Ä°stÉ™sÉ™n bu skriptin hÉ™r hansÄ± hissÉ™si barÉ™dÉ™ É™lavÉ™ izah vÉ™ ya nÃ¼munÉ™ istÉ™yÉ™rsÉ™n.</p>

<h2>ğŸ“ŒTam Kod</h2>

<pre><code>

        """
        AzGPT - AzÉ™rbaycan Dili Ã¼Ã§Ã¼n GPU Optimize EdilmiÅŸ GPT-2 TÉ™lim Skripti
        Ä°nkiÅŸaf etdirilmiÅŸ versiya: TÉ™limin gediÅŸatÄ±nÄ± real-time vizuallaÅŸdÄ±rmaqla
        """
        import json
        import os
        import re
        import time
        import torch
        import numpy as np
        from tqdm import tqdm
        import matplotlib.pyplot as plt
        from glob import glob
        from datetime import datetime
        from datasets import Dataset
        from transformers import (
            GPT2LMHeadModel,
            GPT2Config,
            AutoTokenizer,
            TrainingArguments,
            DataCollatorForLanguageModeling,
            Trainer,
            set_seed
        )

        # ==================== QOVLUQ YOLLARI ====================
        BASE_DIR = r"C:\Users\Mafia\PycharmProjects\MyLLMProject"
        DATA_DIR = os.path.join(BASE_DIR, "telim_ucun")
        TOKENIZER_DIR = os.path.join(BASE_DIR, "azeri_tokenizer")
        OUTPUT_DIR = os.path.join(BASE_DIR, "models", f"azeri_gpt2_{datetime.now().strftime('%Y%m%d_%H%M')}")

        # ==================== TÆLÄ°M PARAMETRLÆRÄ° ====================
        EPOCHS = 15
        BATCH_SIZE = 32
        LEARNING_RATE = 5e-5
        GRADIENT_ACCUMULATION_STEPS = 2
        MAX_SEQ_LENGTH = 256
        SEED = 42

        # GPU konfiqurasiyasÄ±
        set_seed(SEED)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        torch.backends.cuda.matmul.allow_tf32 = True


        class TrainingVisualizer:
            """
            TÉ™lim zamanÄ± itkilÉ™ri (loss) vÉ™ GPU yaddaÅŸ istifadÉ™sini real-time
            qeyd edib, mÃ¼É™yyÉ™n intervallarda konsola statistikalar Ã§ap edir.
            """

            def __init__(self):
                """
                Loss vÉ™ GPU yaddaÅŸÄ±nÄ± saxlamaq Ã¼Ã§Ã¼n siyahÄ±lar yaradÄ±lÄ±r.
                """
                self.train_losses = []
                self.eval_losses = []
                self.gpu_memory = []

            def update(self, logs, gpu_stats):
                """
                HÉ™r yeni log gÉ™lÉ™ndÉ™ loss vÉ™ GPU yaddaÅŸÄ±nÄ± yenilÉ™yir.
                HÉ™r 100 addÄ±mda cari vÉ™ziyyÉ™ti konsola Ã§ap edir.

                ParametrlÉ™r:
                    logs (dict): TÉ™lim vÉ™ validasiya itkilÉ™rini ehtiva edÉ™n sÃ¶zlÃ¼k.
                    gpu_stats (dict): GPU yaddaÅŸ statistikasÄ±.
                """
                if 'loss' in logs:
                    self.train_losses.append(logs['loss'])
                if 'eval_loss' in logs:
                    self.eval_losses.append(logs['eval_loss'])
                if gpu_stats:
                    self.gpu_memory.append(gpu_stats['used'])

                # HÉ™r 100 addÄ±mda bir statistikalarÄ± Ã§ap et
                if len(self.train_losses) % 100 == 0:
                    print(f"\nğŸ“Š Proqress: Step {len(self.train_losses)}")
                    print(f"ğŸ“‰ Train Loss: {self.train_losses[-1]:.4f}")
                    if self.eval_losses:
                        print(f"ğŸ“ˆ Eval Loss: {self.eval_losses[-1]:.4f}")
                    if self.gpu_memory:
                        print(f"ğŸ’¾ GPU Memory: {self.gpu_memory[-1]:.2f} GB")


        class GPUTrainer(Trainer):
            """
            Transformers kitabxanasÄ±nÄ±n Trainer sinifindÉ™n tÃ¶rÉ™dilib.
            TÉ™lim zamanÄ± real-time mÉ™lumatlarÄ± toplayÄ±r, proqress bar gÃ¶stÉ™rir,
            GPU yaddaÅŸ istifadÉ™ni izlÉ™yir, statistikalarÄ± fayla yazÄ±r vÉ™ qrafik yaradÄ±r.
            """

            def __init__(self, *args, **kwargs):
                """
                Valideyn Trainer sinifinin __init__ metodunu Ã§aÄŸÄ±rÄ±r,
                É™lavÉ™ statistikalarÄ± vÉ™ progress bar Ã¼Ã§Ã¼n dÉ™yiÅŸÉ™nlÉ™ri yaradÄ±r.
                """
                super().__init__(*args, **kwargs)
                self.progress_bar = None
                self.stats = {
                    'steps': [],
                    'train_loss': [],
                    'val_loss': [],
                    'learning_rate': [],
                    'gpu_memory': [],
                    'epochs': []
                }
                self.current_epoch = 0
                self.last_log_time = time.time()

            def log(self, logs, start_time=None):
                """
                HÉ™r tÉ™lim addÄ±mÄ±nda Ã§aÄŸÄ±rÄ±lÄ±r, logs daxilindÉ™ olan mÉ™lumatlarÄ±
                toplayÄ±r vÉ™ statistikalarÄ± yenilÉ™yir.
                Progress bar vÉ™ qrafik yenilÉ™mÉ™lÉ™rini idarÉ™ edir.

                ParametrlÉ™r:
                    logs (dict): TÉ™lim vÉ™ validasiya nÉ™ticÉ™lÉ™rini ehtiva edir.
                    start_time (float, opsional): TÉ™lim addÄ±mÄ±nÄ±n baÅŸlanÄŸÄ±c vaxtÄ±.
                """
                super().log(logs)

                # AddÄ±m sayÄ±nÄ± hesablamaq vÉ™ siyahÄ±ya É™lavÉ™ etmÉ™k
                step = len(self.stats['steps']) + 1
                self.stats['steps'].append(step)

                # Loss dÉ™yÉ™rlÉ™rini siyahÄ±lara É™lavÉ™ et
                if 'loss' in logs:
                    self.stats['train_loss'].append(float(logs['loss']))
                if 'eval_loss' in logs:
                    self.stats['val_loss'].append(float(logs['eval_loss']))

                # Ã–yrÉ™nmÉ™ sÃ¼rÉ™tini É™lavÉ™ et
                if 'learning_rate' in logs:
                    self.stats['learning_rate'].append(float(logs['learning_rate']))

                # GPU yaddaÅŸ istifadÉ™ni Ã¶lÃ§ vÉ™ É™lavÉ™ et
                gpu_mem = torch.cuda.memory_allocated() / 1024 ** 3 if torch.cuda.is_available() else 0
                self.stats['gpu_memory'].append(gpu_mem)

                # Hal-hazÄ±rkÄ± epoch-u yenilÉ™
                if 'epoch' in logs:
                    self.current_epoch = float(logs['epoch'])
                self.stats['epochs'].append(self.current_epoch)

                # Progress bar yaradÄ±lmasÄ±
                if self.progress_bar is None:
                    total_steps = self.args.num_train_epochs * len(self.train_dataset) // self.args.per_device_train_batch_size
                    self.progress_bar = tqdm(total=total_steps, desc="ğŸš€ TÉ™lim", dynamic_ncols=True)

                # Progress bar yenilÉ™
                self._update_progress_bar(logs, gpu_mem)

                # HÉ™r 50 addÄ±mda statistikalarÄ± yadda saxla vÉ™ qrafik Ã§É™k
                if step % 50 == 0:
                    self._save_stats()
                    self._plot_progress()

            def _update_progress_bar(self, logs, gpu_mem):
                """
                Progress bar Ã¼zÉ™rindÉ™ cari itki, validasiya itkisi, lr, gpu vÉ™ epoch
                mÉ™lumatlarÄ±nÄ± gÃ¶stÉ™rir.

                ParametrlÉ™r:
                    logs (dict): Cari tÉ™lim addÄ±mÄ± nÉ™ticÉ™lÉ™ri.
                    gpu_mem (float): Cari GPU yaddaÅŸ istifadÉ™ (GB).
                """
                postfix = {}

                # Loss dÉ™yÉ™rlÉ™ri
                train_loss = logs.get('loss')
                val_loss = logs.get('eval_loss')

                postfix['loss'] = f"{float(train_loss):.4f}" if train_loss is not None else 'N/A'
                postfix['val_loss'] = f"{float(val_loss):.4f}" if val_loss is not None else 'N/A'

                # Learning rate
                lr = logs.get('learning_rate')
                postfix['lr'] = f"{float(lr):.1e}" if lr is not None else 'N/A'

                # GPU vÉ™ epoch
                postfix['gpu'] = f"{gpu_mem:.1f}GB"
                postfix['epoch'] = f"{self.current_epoch:.1f}"

                self.progress_bar.set_postfix(postfix)
                self.progress_bar.update(1)

            def _save_stats(self):
                """
                YÄ±ÄŸÄ±lan statistikalarÄ± JSON formatÄ±nda Ã§Ä±xÄ±ÅŸ qovluÄŸunda saxlayÄ±r.
                """
                os.makedirs(self.args.output_dir, exist_ok=True)
                stats_file = os.path.join(self.args.output_dir, "training_stats.json")

                with open(stats_file, 'w', encoding='utf-8') as f:
                    json.dump(self.stats, f, indent=2)

            def _plot_progress(self):
                """
                TÉ™lim itkilÉ™ri, Ã¶yrÉ™nmÉ™ sÃ¼rÉ™ti vÉ™ GPU yaddaÅŸ istifadÉ™sini qrafikÉ™
                Ã§É™kir vÉ™ ÅŸÉ™kil faylÄ± kimi yadda saxlayÄ±r.
                """
                if len(self.stats['steps']) < 2:
                    return

                plt.figure(figsize=(15, 5))

                # Train vÉ™ validation loss qrafiki
                plt.subplot(1, 3, 1)
                plt.plot(self.stats['steps'], self.stats['train_loss'], label='Train Loss')
                if self.stats['val_loss']:
                    val_steps = np.linspace(0, max(self.stats['steps']), len(self.stats['val_loss']))
                    plt.plot(val_steps, self.stats['val_loss'], label='Validation Loss')
                plt.xlabel('Steps')
                plt.ylabel('Loss')
                plt.title('Training Progress')
                plt.legend()
                plt.grid(True)

                # Ã–yrÉ™nmÉ™ sÃ¼rÉ™ti qrafiki
                plt.subplot(1, 3, 2)
                plt.plot(self.stats['steps'], self.stats['learning_rate'])
                plt.xlabel('Steps')
                plt.ylabel('Learning Rate')
                plt.title('Learning Rate Schedule')
                plt.grid(True)

                # GPU yaddaÅŸ istifadÉ™si qrafiki
                plt.subplot(1, 3, 3)
                plt.plot(self.stats['steps'], self.stats['gpu_memory'])
                plt.xlabel('Steps')
                plt.ylabel('GPU Memory (GB)')
                plt.title('GPU Memory Usage')
                plt.grid(True)

                plt.tight_layout()
                plot_path = os.path.join(self.args.output_dir, "training_progress.png")
                plt.savefig(plot_path)
                plt.close()


        class AzerbaijaniGPT2Trainer:
            """
            AzGPT layihÉ™sinin É™sas tÉ™lim sinifi.
            Tokenizer yÃ¼klÉ™nmÉ™si, model konfiqurasiyasÄ±, verilÉ™nlÉ™rin hazÄ±rlanmasÄ±,
            tÉ™limin idarÉ™ olunmasÄ± vÉ™ nÉ™ticÉ™lÉ™rin saxlanmasÄ± bu sinifdÉ™ idarÉ™ olunur.
            """

            def __init__(self, data_dir, tokenizer_dir, output_dir, epochs, batch_size, learning_rate):
                """
                TÉ™lim Ã¼Ã§Ã¼n É™sas parametrlÉ™r burada yadda saxlanÄ±lÄ±r.

                ParametrlÉ™r:
                    data_dir (str): TÉ™lim Ã¼Ã§Ã¼n mÉ™tn fayllarÄ±nÄ±n olduÄŸu qovluq.
                    tokenizer_dir (str): Tokenizer-in saxlandÄ±ÄŸÄ± qovluq.
                    output_dir (str): TÉ™lim nÉ™ticÉ™lÉ™rinin saxlanacaÄŸÄ± qovluq.
                    epochs (int): TÉ™lim dÃ¶vrlÉ™rinin sayÄ±.
                    batch_size (int): Bir batch-dÉ™ nÃ¼munÉ™lÉ™rin sayÄ±.
                    learning_rate (float): Ã–yrÉ™nmÉ™ sÃ¼rÉ™ti.
                """
                self.data_dir = data_dir
                self.tokenizer_dir = tokenizer_dir
                self.output_dir = output_dir
                self.epochs = epochs
                self.batch_size = batch_size
                self.learning_rate = learning_rate
                self.device = device
                self.tokenizer = None
                self.model = None
                self.trainer = None

            def _print_configuration(self):
                """
                Cari tÉ™lim parametrlÉ™rini vÉ™ GPU konfiqurasiyasÄ±nÄ± konsola Ã§ap edir.
                """
                print("\n=== TÆLÄ°M KONFÄ°QURASÄ°YASI ===")
                print(f"ğŸ”µ Model: GPT-2 (Azerbaijani)")
                print(f"ğŸ”µ TÉ™lim dÃ¶vrlÉ™ri: {self.epochs}")
                print(f"ğŸ”µ Batch Ã¶lÃ§Ã¼sÃ¼: {self.batch_size}")
                print(f"ğŸ”µ Effektiv batch: {self.batch_size * GRADIENT_ACCUMULATION_STEPS}")
                print(f"ğŸ”µ Ã–yrÉ™nmÉ™ sÃ¼rÉ™ti: {self.learning_rate}")
                print(f"ğŸ”µ Maksimum ardÄ±cÄ±llÄ±q uzunluÄŸu: {MAX_SEQ_LENGTH}")
                print(f"ğŸ”µ Ã‡Ä±xÄ±ÅŸ qovluÄŸu: {self.output_dir}")

                if torch.cuda.is_available():
                    print("\n=== GPU KONFÄ°QURASÄ°YASI ===")
                    print(f"ğŸ”µ GPU: {torch.cuda.get_device_name(0)}")
                    print(f"ğŸ”µ CUDA versiyasÄ±: {torch.version.cuda}")
                    print(f"ğŸ”µ Ãœmumi yaddaÅŸ: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.2f} GB")
                    print(f"ğŸ”µ PyTorch versiyasÄ±: {torch.__version__}")

                print("\nğŸš€ TÉ™lim konfiqurasiyasÄ± hazÄ±rdÄ±r...\n")

            def initialize_tokenizer(self):
                """
                Tokenizer-in diskdÉ™n yÃ¼klÉ™nmÉ™si vÉ™ lazÄ±m olduqda pad_token-un tÉ™yin olunmasÄ±.
                """
                print("ğŸ”  Tokenizer yÃ¼klÉ™nir...")
                self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_dir)

                # ÆgÉ™r pad token yoxdursa, eos_token-u pad token kimi tÉ™yin et
                if self.tokenizer.pad_token is None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token

                print(f"âœ… Tokenizer uÄŸurla yÃ¼klÉ™ndi (Real sÃ¶zlÃ¼k Ã¶lÃ§Ã¼sÃ¼: {len(self.tokenizer)})")

            def initialize_model(self):
                """
                GPT-2 modelinin konfiqurasiyasÄ±nÄ± tÉ™yin edir vÉ™ model nÃ¼munÉ™sini yaradÄ±r.
                Model sonra device-a (GPU/CPU) Ã¶tÃ¼rÃ¼lÃ¼r.
                """
                print("\nğŸ§  Model konfiqurasiyasÄ± hazÄ±rlanÄ±r...")
                config = GPT2Config(
                    vocab_size=len(self.tokenizer),  # Tokenizer-in sÃ¶zlÃ¼k Ã¶lÃ§Ã¼sÃ¼nÉ™ uyÄŸun olmalÄ±dÄ±r
                    n_positions=MAX_SEQ_LENGTH,
                    n_embd=768,
                    n_layer=8,
                    n_head=8,
                    pad_token_id=self.tokenizer.pad_token_id,
                    bos_token_id=self.tokenizer.bos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id,
                    resid_pdrop=0.1,
                    embd_pdrop=0.1,
                    attn_pdrop=0.1,
                    gradient_checkpointing=True  # YaddaÅŸÄ± qÉ™naÉ™t etmÉ™k Ã¼Ã§Ã¼n
                )
                self.model = GPT2LMHeadModel(config).to(self.device)
                print(f"âœ… Model yaradÄ±ldÄ± (Vocab size: {config.vocab_size})")

            def prepare_data(self):
                """
                MÉ™tn fayllarÄ±nÄ± oxuyur, tÉ™mizlÉ™yir, cÃ¼mlÉ™lÉ™rÉ™ bÃ¶lÃ¼r vÉ™
                Dataset formatÄ±na Ã§evirir. Sonra tokenlÉ™ÅŸdirir vÉ™ tÉ™lim-test
                bÃ¶lmÉ™sini yaradÄ±r.

                Geri dÃ¶nÉ™n dÉ™yÉ™r:
                    split_dataset (DatasetDict): TÉ™lim vÉ™ test datasÄ±nÄ± saxlayan obyekt.
                """
                print("\nğŸ“Š MÉ™lumatlar hazÄ±rlanÄ±r...")
                txt_files = glob(os.path.join(self.data_dir, "*.txt"))
                print(f"ğŸ“‚ {len(txt_files)} fayl aÅŸkar edildi")

                texts = []
                for file_path in tqdm(txt_files, desc="Fayllar oxunur"):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        # CÃ¼mlÉ™lÉ™rÉ™ bÃ¶l, artÄ±q boÅŸluqlarÄ± azaldÄ±r vÉ™ 10-dan uzun olanlarÄ± saxla
                        sentences = [re.sub(r'\s+', ' ', s).strip() for s in content.split('.') if len(s) > 10]
                        # CÃ¼mlÉ™ uzunluÄŸu 20 ilÉ™ 500 arasÄ± olanlarÄ± saxla
                        texts.extend([{"text": s} for s in sentences if 20 < len(s) < 500])

                dataset = Dataset.from_list(texts)
                print(f"ğŸ“Š Ãœmumi {len(dataset)} nÃ¼munÉ™ hazÄ±rlandÄ±")

                def tokenize_function(examples):
                    """
                    Dataset.map funksiyasÄ± Ã¼Ã§Ã¼n tokenize funksiyasÄ±.
                    """
                    return self.tokenizer(
                        examples["text"],
                        truncation=True,
                        max_length=MAX_SEQ_LENGTH,
                        padding="max_length",
                        add_special_tokens=True
                    )

                print("ğŸ”¢ MÉ™lumatlar tokenlÉ™ÅŸdirilir...")
                tokenized_dataset = dataset.map(tokenize_function, batched=True,
                                                remove_columns=["text"],
                                                desc="TokenlÉ™ÅŸdirilir")

                split_dataset = tokenized_dataset.train_test_split(test_size=0.1)
                print(
                    f"âœ‚ï¸ MÉ™lumatlar bÃ¶lÃ¼ndÃ¼: TÉ™lim - {len(split_dataset['train'])}, Validasiya - {len(split_dataset['test'])}")
                return split_dataset

            def train(self):
                """
                TÉ™lim prosesini idarÉ™ edir:
                - Ã‡Ä±xÄ±ÅŸ qovluÄŸunu yaradÄ±r,
                - KonfiqurasiyanÄ± Ã§ap edir,
                - Tokenizer vÉ™ modeli yÃ¼klÉ™yir,
                - Dataseti hazÄ±rlayÄ±r,
                - TrainingArguments vÉ™ DataCollator yaradÄ±r,
                - GPUTrainer sinifindÉ™n tÉ™lim obyektini yaradÄ±r,
                - TÉ™limi baÅŸlayÄ±r vÉ™ yadda saxlayÄ±r.
                """
                os.makedirs(self.output_dir, exist_ok=True)
                self._print_configuration()

                self.initialize_tokenizer()
                self.initialize_model()
                split_dataset = self.prepare_data()

                training_args = TrainingArguments(
                    output_dir=self.output_dir,
                    num_train_epochs=self.epochs,
                    per_device_train_batch_size=self.batch_size,
                    per_device_eval_batch_size=self.batch_size,
                    learning_rate=self.learning_rate,
                    weight_decay=0.01,
                    warmup_steps=1000,
                    save_steps=1000,
                    logging_steps=100,
                    eval_strategy="steps",
                    eval_steps=500,
                    fp16=True,
                    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,
                    report_to="none",
                    save_total_limit=2,
                    load_best_model_at_end=True,
                    metric_for_best_model="eval_loss",
                    greater_is_better=False,
                    optim="adamw_torch_fused",
                    dataloader_pin_memory=True,
                    dataloader_num_workers=4,
                    seed=SEED
                )

                data_collator = DataCollatorForLanguageModeling(
                    tokenizer=self.tokenizer,
                    mlm=False  # GPT-2 Ã¼Ã§Ã¼n MLM istifadÉ™ edilmir
                )

                self.trainer = GPUTrainer(
                    model=self.model,
                    args=training_args,
                    train_dataset=split_dataset["train"],
                    eval_dataset=split_dataset["test"],
                    data_collator=data_collator,
                )

                print("\nğŸš€ TÉ™lim baÅŸlayÄ±r...")
                try:
                    self.trainer.train()
                except RuntimeError as e:
                    # CUDA yaddaÅŸ problemi yaranarsa xÉ™bÉ™r ver vÉ™ batch Ã¶lÃ§Ã¼sÃ¼nÃ¼ azaltmaÄŸÄ± tÉ™klif et
                    if "CUDA out of memory" in str(e):
                        print("\nâŒ GPU yaddaÅŸÄ± Ã§oxdur! Batch Ã¶lÃ§Ã¼sÃ¼nÃ¼ azaldÄ±n.")
                        print(f"   TÉ™vsiyÉ™: batch_size={max(1, self.batch_size // 2)}")
                    raise

                # Model vÉ™ tokenizer-i yadda saxla
                self.trainer.save_model(self.output_dir)
                self.tokenizer.save_pretrained(self.output_dir)

                print(f"\nâœ… Model qeyd edildi: {self.output_dir}")

                # ÆgÉ™r visualizer varsa, son qrafiki yadda saxla
                if hasattr(self.trainer, 'visualizer') and self.trainer.visualizer.train_losses:
                    final_plot_path = os.path.join(self.output_dir, "final_training_progress.png")
                    self.trainer.visualizer.fig.savefig(final_plot_path)
                    print(f"ğŸ“Š TÉ™lim qrafiki yadda saxlanÄ±ldÄ±: {final_plot_path}")


        def main():
            """
            ProqramÄ±n giriÅŸ nÃ¶qtÉ™si.
            MÉ™lumat qovluqlarÄ±nÄ±n mÃ¶vcudluÄŸunu yoxlayÄ±r,
            GPU mÃ¶vcudluÄŸunu yoxlayÄ±r,
            TÉ™lim sinifini iÅŸÉ™ salÄ±r vÉ™ nÉ™ticÉ™ni Ã§ap edir.
            """
            print("=" * 50)
            print("AZGPT - AzÉ™rbaycan Dili Ã¼Ã§Ã¼n GPT-2 TÉ™lim ProqramÄ±")
            print(f"BaÅŸlama vaxtÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("=" * 50)

            if not os.path.exists(DATA_DIR):
                raise ValueError(f"âŒ MÉ™lumat qovluÄŸu tapÄ±lmadÄ±: {DATA_DIR}")
            if not os.path.exists(TOKENIZER_DIR):
                raise ValueError(f"âŒ Tokenizer qovluÄŸu tapÄ±lmadÄ±: {TOKENIZER_DIR}")

            if not torch.cuda.is_available():
                raise RuntimeError("""
                âŒ GPU aÅŸkarlanmadÄ±!

                ZÉ™hmÉ™t olmasa:
                1. NVIDIA GPU-nuz olduÄŸuna É™min olun
                2. CUDA drayverlÉ™rini quraÅŸdÄ±rÄ±n
                3. PyTorch GPU versiyasÄ±nÄ± quraÅŸdÄ±rÄ±n:
                   `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`
                """)

            trainer = AzerbaijaniGPT2Trainer(
                data_dir=DATA_DIR,
                tokenizer_dir=TOKENIZER_DIR,
                output_dir=OUTPUT_DIR,
                epochs=EPOCHS,
                batch_size=BATCH_SIZE,
                learning_rate=LEARNING_RATE
            )

            try:
                trainer.train()
            except Exception as e:
                print(f"\nâŒ XÉ™ta baÅŸ verdi: {str(e)}")
                raise
            finally:
                print("\n" + "=" * 50)
                print(f"TÉ™lim tamamlandÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                print("=" * 50)


        if __name__ == "__main__":
            torch.cuda.empty_cache()
            main()


</code></pre>

</body>
</html>
