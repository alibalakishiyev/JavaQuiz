<!DOCTYPE html>
<html lang="az">
<head>
    <meta charset="UTF-8">
    <title>n_positions AÃ§Ä±qlamasÄ±</title>
    <style>
        body {
          font-family: "Segoe UI", sans-serif;
          padding: 30px;
          background-color: #f9f9f9;
          color: #333;
        }
        h1, h2 {
          color: #2c3e50;
        }
        .code-block {
          background-color: #eef;
          padding: 10px;
          border-radius: 6px;
          font-family: Consolas, monospace;
          margin: 10px 0;
        }
        .highlight {
          background-color: #fff3cd;
          border-left: 6px solid #ffc107;
          padding: 10px;
          margin: 20px 0;
        }
        .formula {
            background: #e3f2fd;
            border-left: 6px solid #2196f3;
            padding: 10px;
            margin: 15px 0;
            font-family: monospace;
            color: black;
        }
        .note {
          background-color: #e8f5e9;
          padding: 10px;
          border-left: 6px solid #66bb6a;
          margin: 10px 0;
        }
    </style>
</head>
<body>

<h1>ğŸ§­ <code>n_positions = 512</code> AÃ§Ä±qlamasÄ±</h1>

<div class="formula">
    config = GPT2Config(<br>
    &nbsp;&nbsp;&nbsp;&nbsp;n_positions = 512,<br>
    &nbsp;&nbsp;&nbsp;&nbsp;...<br>
    )
</div>

<h2>ğŸ“Œ NÉ™ demÉ™kdir?</h2>
<div class="formula">
    <strong><code>n_positions</code></strong> â€” Transformer modelinin giriÅŸindÉ™ki maksimum ardÄ±cÄ±llÄ±q (sequence) uzunluÄŸudur.
    <br><br>
    YÉ™ni model bir dÉ™fÉ™lik giriÅŸdÉ™ **É™n Ã§ox neÃ§É™ token** emal edÉ™ bilÉ™cÉ™yini gÃ¶stÉ™rir.
</div>

<h2>ğŸ’¡ Riyazi mÉ™na</h2>
<div class="formula">
    Maksimum ardÄ±cÄ±llÄ±q uzunluÄŸu = <strong>n_positions</strong> = 512
</div>

<h3>MÉ™sÉ™lÉ™n:</h3>
<div class="formula">
    GiriÅŸ: "AzÉ™rbaycan RespublikasÄ±nÄ±n DÃ¶vlÉ™t Vergi XidmÉ™ti..."<br>
    Token sayÄ±sÄ±: 97 â†’ OK âœ…<br>
    Token sayÄ±sÄ±: 600 â†’ Truncation olacaq âŒ
</div>

<h2>ğŸ“Š MÃ¶vqeli embeddinglÉ™r necÉ™ iÅŸlÉ™yir?</h2>
<div class="formula">
    TransformerlÉ™r tÉ™bii olaraq sÄ±ranÄ± anlamÄ±r (seqential bias yoxdur). Ona gÃ¶rÉ™ dÉ™:
    <br><br>
    <strong>Position Embedding</strong> É™lavÉ™ olunur ki, model 1-ci, 2-ci, 3-cÃ¼ token fÉ™rqini Ã¶yrÉ™nsin.
</div>

<h2>ğŸ“ Hesablama: Position Embedding Matrisi</h2>
<div class="formula">
    MÃ¶vqe matrisi Ã¶lÃ§Ã¼sÃ¼ = n_positions Ã— n_embd
</div>

<h3>ÆgÉ™r:</h3>
<div class="formula">
    n_positions = 512<br>
    n_embd = 768<br><br>
    â¤ Position embedding matrisi = 512 Ã— 768 = <strong>393,216</strong> parametr
</div>

<h2>âš ï¸ DiqqÉ™t!</h2>
<div class="formula">
    ÆgÉ™r modelin giriÅŸindÉ™ki token sayÄ± <strong>n_positions</strong>-dan bÃ¶yÃ¼k olarsa,<br>
    o zaman É™lavÉ™ tokenlÉ™r <strong>kÉ™silÉ™cÉ™k (truncation)</strong> vÉ™ model onlarÄ± gÃ¶rmÉ™yÉ™cÉ™k.
</div>

<h2>ğŸ§  NÉ™ticÉ™</h2>
<div class="formula">
    <ul>
        <li><strong><code>n_positions</code></strong> modelin gÃ¶rmÉ™ sahÉ™sini mÃ¼É™yyÉ™n edir.</li>
        <li>Daha bÃ¶yÃ¼k dÉ™yÉ™rlÉ™r â†’ daha uzun kontekst, lakin daha Ã§ox yaddaÅŸ vÉ™ hesablama xÉ™rci.</li>
        <li>Daha kiÃ§ik dÉ™yÉ™rlÉ™r â†’ sÃ¼rÉ™t vÉ™ qÉ™naÉ™t, lakin mÉ™hdud kontekst.</li>
    </ul>
</div>

</body>
</html>
