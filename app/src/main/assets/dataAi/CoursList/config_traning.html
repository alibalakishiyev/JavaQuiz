<!DOCTYPE html>
<html lang="az">
<head>
    <meta charset="UTF-8" />
    <title>TrainingArguments ParametrlÉ™rinin Ä°zahÄ±</title>
    <style>
        body {
          font-family: Arial, sans-serif;
          padding: 30px;
          background-color: #f7f9fc;
          color: #2c3e50;
          line-height: 1.7;
        }
        h1, h2 {
          color: #2c3e50;
        }
        .code {
          background: #eef;
          padding: 8px 12px;
          border-left: 4px solid #3498db;
          font-family: Consolas, monospace;
          margin: 10px 0;

        }
        .note {
          background: #e8f5e9;
          border-left: 6px solid #4caf50;
          padding: 10px;
          margin: 20px 0;
        }
        .warn {
          background: #fff3cd;
          border-left: 6px solid #ffc107;
          padding: 10px;
          margin: 20px 0;
        }
        .formula {
            background: #e3f2fd;
            border-left: 6px solid #2196f3;
            padding: 10px;
            margin: 15px 0;
            font-family: monospace;
            color: black;
        }
        ul {
          margin-left: 20px;
        }
    </style>
</head>
<body>

<h1>ğŸ¤– <code>TrainingArguments</code> ParametrlÉ™rinin Tam Ä°zahÄ±</h1>

<section>
    <h2><code>output_dir</code></h2>
    <p><strong>TÉ™svir:</strong> TÉ™limdÉ™n sonra model vÉ™ yoxlama fayllarÄ±nÄ±n saxlanacaÄŸÄ± qovluq.</p>
    <p><strong>Misal:</strong> <code>"models/azeri_gpt2_gpu"</code></p>
</section>

<section>
    <h2><code>num_train_epochs</code></h2>
    <p><strong>TÉ™svir:</strong> Modelin tam mÉ™lumat dÉ™sti Ã¼zÉ™rindÉ™ neÃ§É™ dÉ™fÉ™ tÉ™krar tÉ™lim edilÉ™cÉ™yi (epoch sayÄ±).</p>
    <p><strong>Misal:</strong> 5 epoch mÉ™lumatÄ± 5 dÉ™fÉ™ tam iÅŸlÉ™yir.</p>
</section>

<section>
    <h2><code>per_device_train_batch_size</code></h2>
    <p><strong>TÉ™svir:</strong> HÉ™r bir cihaz (GPU/CPU) Ã¼Ã§Ã¼n mini-batch Ã¶lÃ§Ã¼sÃ¼.</p>
    <p><strong>ÆhÉ™miyyÉ™ti:</strong> Batch Ã¶lÃ§Ã¼sÃ¼ tÉ™lim performansÄ±nÄ± vÉ™ yaddaÅŸ istifadÉ™sini birbaÅŸa tÉ™sir edir.</p>
    <p><strong>Misal:</strong> 16 nÃ¼munÉ™ bir batch-da emal olunur.</p>
</section>

<section>
    <h2><code>per_device_eval_batch_size</code></h2>
    <p><strong>TÉ™svir:</strong> QiymÉ™tlÉ™ndirmÉ™ zamanÄ± hÉ™r cihazda istifadÉ™ olunan batch Ã¶lÃ§Ã¼sÃ¼.</p>
    <p><strong>Misal:</strong> TÉ™limdÉ™ki batch Ã¶lÃ§Ã¼sÃ¼ ilÉ™ eyni 16.</p>
</section>

<section>
    <h2><code>learning_rate</code></h2>
    <p><strong>TÉ™svir:</strong> Modelin Ã§É™kilÉ™rini yenilÉ™mÉ™ sÃ¼rÉ™ti (Ã¶yrÉ™nmÉ™ sÃ¼rÉ™ti).</p>
    <p><strong>ÆhÉ™miyyÉ™ti:</strong> KiÃ§ik dÉ™yÉ™rlÉ™r modelin daha sabit vÉ™ yavaÅŸ Ã¶yrÉ™nmÉ™sini tÉ™min edir; bÃ¶yÃ¼k dÉ™yÉ™rlÉ™r isÉ™ sÃ¼rÉ™tli amma qeyri-sabit Ã¶yrÉ™nmÉ™ yarada bilÉ™r.</p>
    <p><strong>Misal:</strong> 3e-5 (0.00003)</p>
</section>

<section>
    <h2><code>weight_decay</code></h2>
    <p><strong>TÉ™svir:</strong> Overfitting-in qarÅŸÄ±sÄ±nÄ± almaq Ã¼Ã§Ã¼n Ã§É™kilÉ™rÉ™ tÉ™tbiq olunan azalmanÄ±n dÉ™rÉ™cÉ™si (regularization).</p>
    <p><strong>Misal:</strong> 0.01 - kiÃ§ik, amma faydalÄ± bir azalma.</p>
</section>

<section>
    <h2><code>warmup_steps</code></h2>
    <p><strong>TÉ™svir:</strong> TÉ™limin É™vvÉ™lindÉ™ Ã¶yrÉ™nmÉ™ sÃ¼rÉ™tinin tÉ™dricÉ™n artacaÄŸÄ± addÄ±mlarÄ±n sayÄ±.</p>
    <p><strong>ÆhÉ™miyyÉ™ti:</strong> Modelin tÉ™limÉ™ daha stabil baÅŸlamasÄ±nÄ± tÉ™min edir.</p>
    <p><strong>Misal:</strong> 500 addÄ±m</p>
</section>

<section>
    <h2><code>save_steps</code></h2>
    <p><strong>TÉ™svir:</strong> HÉ™r neÃ§É™ addÄ±mdan sonra modelin checkpoint (ehtiyat surÉ™ti) saxlanacaq.</p>
    <p><strong>Misal:</strong> HÉ™r 1000 addÄ±mda model yaddaÅŸa yazÄ±lÄ±r.</p>
</section>

<section>
    <h2><code>logging_steps</code></h2>
    <p><strong>TÉ™svir:</strong> TÉ™lim zamanÄ± statistikanÄ±n (loss, learning rate vÉ™ s.) neÃ§É™ addÄ±mdan bir konsola yazÄ±lacaÄŸÄ±.</p>
    <p><strong>Misal:</strong> HÉ™r 100 addÄ±mda.</p>
</section>

<section>
    <h2><code>eval_strategy</code></h2>
    <p><strong>TÉ™svir:</strong> QiymÉ™tlÉ™ndirmÉ™ (evaluation) strategiyasÄ±.</p>
    <p><strong>SeÃ§imlÉ™r:</strong> <code>"no"</code> (qiymÉ™tlÉ™ndirmÉ™ yoxdur), <code>"steps"</code> (mÃ¼É™yyÉ™n addÄ±mlardan sonra qiymÉ™tlÉ™ndirmÉ™), <code>"epoch"</code> (hÉ™r epoch sonunda).</p>
    <p><strong>Misal:</strong> <code>"steps"</code> - hÉ™r mÃ¼É™yyÉ™n addÄ±mda test set ilÉ™ yoxlama.</p>
</section>

<section>
    <h2><code>eval_steps</code></h2>
    <p><strong>TÉ™svir:</strong> QiymÉ™tlÉ™ndirmÉ™nin neÃ§É™ addÄ±mdan bir aparÄ±lacaÄŸÄ±.</p>
    <p><strong>Misal:</strong> HÉ™r 500 addÄ±mda qiymÉ™tlÉ™ndirmÉ™ edilir.</p>
</section>

<section>
    <h2><code>fp16</code></h2>
    <p><strong>TÉ™svir:</strong> YarÄ±m dÉ™qiqlikli 16-bit float tÉ™limin aktivlÉ™ÅŸdirilmÉ™si (mixed precision training).</p>
    <p><strong>FaydasÄ±:</strong> GPU yaddaÅŸÄ±na qÉ™naÉ™t vÉ™ sÃ¼rÉ™t artÄ±mÄ±.</p>
    <p><strong>Qeyd:</strong> YalnÄ±z uyÄŸun GPU-larda iÅŸlÉ™yir.</p>
</section>

<section>
    <h2><code>gradient_accumulation_steps</code></h2>
    <p><strong>TÉ™svir:</strong> GradientlÉ™rin neÃ§É™ addÄ±mda yÄ±ÄŸÄ±lÄ±b yenilÉ™nÉ™cÉ™yini gÃ¶stÉ™rir.</p>
    <p><strong>ÆhÉ™miyyÉ™ti:</strong> Effektiv batch Ã¶lÃ§Ã¼sÃ¼nÃ¼ artÄ±rmaq Ã¼Ã§Ã¼n istifadÉ™ olunur.</p>
    <p><strong>Misal:</strong> Batch=16, accumulation=4 isÉ™ effektiv batch = 64 olur.</p>
</section>

<section>
    <h2><code>report_to</code></h2>
    <p><strong>TÉ™svir:</strong> TÉ™lim prosesinin hansÄ± platformaya hesabat verÉ™cÉ™yini gÃ¶stÉ™rir.</p>
    <p><strong>Misal:</strong> <code>"none"</code> - heÃ§ bir hesabat platformasÄ±, <code>"tensorboard"</code> vÉ™ ya <code>"wandb"</code> ola bilÉ™r.</p>
</section>

<section>
    <h2><code>save_total_limit</code></h2>
    <p><strong>TÉ™svir:</strong> Saxlanacaq maksimum checkpoint sayÄ±.</p>
    <p><strong>Qeyd:</strong> KÃ¶hnÉ™ fayllar avtomatik silinir.</p>
    <p><strong>Misal:</strong> 2</p>
</section>

<section>
    <h2><code>load_best_model_at_end</code></h2>
    <p><strong>TÉ™svir:</strong> TÉ™lim sonunda É™n yaxÅŸÄ± qiymÉ™tlÉ™ndirmÉ™ nÉ™ticÉ™si verÉ™n model yÃ¼klÉ™nÉ™cÉ™k.</p>
</section>

<section>
    <h2><code>metric_for_best_model</code></h2>
    <p><strong>TÉ™svir:</strong> Æn yaxÅŸÄ± modelin seÃ§ilmÉ™sindÉ™ istifadÉ™ olunan qiymÉ™tlÉ™ndirmÉ™ metriqasÄ±.</p>
    <p><strong>Misal:</strong> <code>"eval_loss"</code></p>
</section>

<section>
    <h2><code>greater_is_better</code></h2>
    <p><strong>TÉ™svir:</strong> Metric-in yÃ¼ksÉ™k olmasÄ± model Ã¼Ã§Ã¼n yaxÅŸÄ±dÄ±r, yoxsa aÅŸaÄŸÄ±?</p>
    <p><strong>Misal:</strong> Loss Ã¼Ã§Ã¼n <code>False</code> (az olmasÄ± yaxÅŸÄ±dÄ±r).</p>
</section>

<section>
    <h2><code>optim</code></h2>
    <p><strong>TÉ™svir:</strong> Ä°stifadÉ™ olunan optimizatorun nÃ¶vÃ¼.</p>
    <p><strong>Misal:</strong> <code>"adamw_torch_fused"</code> - GPU Ã¼Ã§Ã¼n sÃ¼rÉ™tli AdamW optimizatoru.</p>
</section>

<section>
    <h2><code>dataloader_pin_memory</code></h2>
    <p><strong>TÉ™svir:</strong> DataLoader-da pin_memory seÃ§imini aktiv edir.</p>
    <p><strong>FaydasÄ±:</strong> GPU-ya data Ã¶tÃ¼rÃ¼lmÉ™sini sÃ¼rÉ™tlÉ™ndirir.</p>
</section>

<section>
    <h2><code>dataloader_num_workers</code></h2>
    <p><strong>TÉ™svir:</strong> DataLoader Ã¼Ã§Ã¼n paralel iÅŸlÉ™yÉ™n iÅŸÃ§i (worker) sayÄ±.</p>
    <p><strong>FaydasÄ±:</strong> Data yÃ¼klÉ™nmÉ™ sÃ¼rÉ™tini artÄ±rÄ±r.</p>
    <p><strong>Misal:</strong> 4 iÅŸÃ§i</p>
</section>

<section>
    <h2><code>seed</code></h2>
    <p><strong>TÉ™svir:</strong> TÉ™sadÃ¼fi É™dÉ™dlÉ™rin baÅŸlanÄŸÄ±c toxumu, nÉ™ticÉ™lÉ™rin tÉ™krar olunmasÄ± Ã¼Ã§Ã¼n vacibdir.</p>
    <p><strong>Misal:</strong> 42</p>
</section>

<h2>ğŸ“ŒTam Kod</h2>

<pre><code>
    from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir=self.output_dir,                # âœ… Model vÉ™ log fayllarÄ±nÄ±n saxlanacaÄŸÄ± qovluq
    num_train_epochs=self.epochs,              # âœ… TÉ™limin neÃ§É™ tam dÃ¶vr (epoch) aparÄ±lacaÄŸÄ±
    per_device_train_batch_size=self.batch_size,     # âœ… HÉ™r GPU/CPU Ã¼Ã§Ã¼n tÉ™lim zamanÄ± batch Ã¶lÃ§Ã¼sÃ¼
    per_device_eval_batch_size=self.batch_size,      # âœ… QiymÉ™tlÉ™ndirmÉ™ zamanÄ± batch Ã¶lÃ§Ã¼sÃ¼

    learning_rate=self.learning_rate,          # âœ… Model Ã§É™kilÉ™rini yenilÉ™mÉ™k Ã¼Ã§Ã¼n Ã¶yrÉ™nmÉ™ sÃ¼rÉ™ti
    weight_decay=0.01,                         # âœ… Overfitting-in qarÅŸÄ±sÄ±nÄ± almaq Ã¼Ã§Ã¼n Ã§É™kilÉ™rÉ™ tÉ™tbiq olunan decay

    warmup_steps=500,                          # âœ… TÉ™limin É™vvÉ™lindÉ™ Ã¶yrÉ™nmÉ™ sÃ¼rÉ™tinin yavaÅŸ-yavaÅŸ artÄ±rÄ±ldÄ±ÄŸÄ± addÄ±m sayÄ±

    save_steps=1000,                           # âœ… HÉ™r 1000 addÄ±mdan bir model checkpoint olaraq yadda saxlanacaq
    logging_steps=100,                         # âœ… HÉ™r 100 addÄ±mdan bir tÉ™lim statistikasÄ± (loss vÉ™ s.) Ã§Ä±xacaq

    eval_strategy="steps",                     # âœ… QiymÉ™tlÉ™ndirmÉ™ strategiyasÄ±: mÃ¼É™yyÉ™n addÄ±mlardan bir yoxlama
    eval_steps=500,                            # âœ… HÉ™r 500 addÄ±mda test set ilÉ™ qiymÉ™tlÉ™ndirmÉ™ aparÄ±lÄ±r

    fp16=True,                                 # âœ… Mixed precision tÉ™lim (GPU-da 16-bit float ilÉ™ sÃ¼rÉ™tli vÉ™ az yaddaÅŸlÄ±)
    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,  # âœ… GradientlÉ™r neÃ§É™ addÄ±mda bir yÄ±ÄŸÄ±lÄ±b optimallaÅŸdÄ±rÄ±lacaq

    report_to="none",                          # âœ… TÉ™lim prosesi heÃ§ bir izlÉ™mÉ™ sisteminÉ™ gÃ¶ndÉ™rilmir (mÉ™s. TensorBoard, WandB)

    save_total_limit=2,                        # âœ… YalnÄ±z son 2 model checkpoint saxlanacaq, qalanlar silinÉ™cÉ™k

    load_best_model_at_end=True,              # âœ… TÉ™lim bitdikdÉ™n sonra É™n aÅŸaÄŸÄ± eval loss olan model yÃ¼klÉ™nÉ™cÉ™k
    metric_for_best_model="eval_loss",        # âœ… Æn yaxÅŸÄ± modeli seÃ§mÉ™k Ã¼Ã§Ã¼n istifadÉ™ edilÉ™n metrik: test loss
    greater_is_better=False,                  # âœ… AÅŸaÄŸÄ± eval_loss daha yaxÅŸÄ± sayÄ±lÄ±r

    optim="adamw_torch_fused",                # âœ… GPU Ã¼Ã§Ã¼n optimallaÅŸdÄ±rÄ±lmÄ±ÅŸ AdamW optimizatoru (fused versiyasÄ±)
    dataloader_pin_memory=True,               # âœ… Dataloader RAM-dan GPU-ya data Ã¶tÃ¼rmÉ™ni sÃ¼rÉ™tlÉ™ndirir
    dataloader_num_workers=4,                 # âœ… Dataloader Ã¼Ã§Ã¼n paralel iÅŸlÉ™yÉ™n iÅŸÃ§i sayÄ± (data yÃ¼klÉ™mÉ™ sÃ¼rÉ™tini artÄ±rÄ±r)

    seed=SEED                                 # âœ… NÉ™ticÉ™lÉ™rin reproduksiyasÄ± Ã¼Ã§Ã¼n random toxum (random_state)
)

</code></pre>

</body>
</html>
